{"pageProps":{"member":{"id":"yteraoka","name":"yteraoka","role":"SRE","bio":"ojisan","avatarSrc":"/avatars/yteraoka.jpeg","sources":["https://blog.1q77.com/feed/","https://qiita.com/yteraoka/feed","https://medium.com/feed/@yteraoka","https://zenn.dev/yteraoka/feed"],"includeUrlRegex":"","twitterUsername":"yteraoka","githubUsername":"yteraoka","websiteUrl":"https://blog.1q77.com/"},"postItems":[{"title":"Graceful Node Shutdown で Terminated 状態で残る Pod を削除する cronjob","contentSnippet":"GKE (GKE 限定な話ではないけれども) で Preemptible な node を使用していると Graceful Node Shutdown により停止させられた Pod が Failed 状態でどんどん溜まっていって結構邪魔です。 できれば消えて欲しい。 ということで削除するための cronjob を deploy するための Helm chart を書いてみた。 GitHub - yteraoka/terminated-pod-cleaner: Graceful Node Shutdown によって Failed になった Pod を掃除する cronjobGraceful Node Shutdown によって Failed になった Pod を掃除する cronjob - GitHub - yteraoka/terminated-pod-cleaner: Graceful Node Shutdown によって Failed になった […]Graceful Node Shutdown で Terminated 状態で残る Pod を削除する cronjob first appeared on 1Q77.","link":"https://blog.1q77.com/2022/08/delete-failed-pod-periodically/","isoDate":"2022-08-12T12:19:57.000Z","dateMiliSeconds":1660306797000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"envoy-sidecar-helper で Job の終了後に istio-proxy を停止させる","contentSnippet":"Istio を導入した環境で Job (CronJob) を実行すると、sidecar としての istio-proxy コンテナを Job 本来の処理が終わった後に istio-proxy コンテナを終了させないといつまで経っても Pod が終了しないという課題があります。 Istio に限らず、Job から生成される Pod の場合、一つでもコンテナが終了せずに残っていれば発生する問題で、例えば Cloud SQL Proxy を sidecar で実行する場合にも同じ問題が発生します。 Istio 環境で動かすことを前提にしたコンテナイメージを作ったり、Helm Chart などのマニフェストを用意する場合コンテナイメージに仕込んだり、Helm の template で Init Container を追加して wrapper script を仕込んだりすることは可能ですが、Deployment ではそんなことを気にする必要がないのに Job だけ特別な対応が必要になるのはなんだか許せないと思うこともあるでしょう。 そんな場合に使えるのが envoy-sidecar-helper です。 envoy-sidecar-helper を sidecar として追加してやると、Kubernetes の API サーバーに定期的に Pod の情報を問い合わせ、メインの処理をしているコンテナが終了しているかどうかを監視し、終了していれば envoy を停止させてくれます。 […]envoy-sidecar-helper で Job の終了後に istio-proxy を停止させる first appeared on 1Q77.","link":"https://blog.1q77.com/2022/08/stop-istio-proxy-using-envoy-sidecar-helper/","isoDate":"2022-08-12T11:51:14.000Z","dateMiliSeconds":1660305074000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"GKE Service の NEG を Terraform で作成する","contentSnippet":"GKE の Ingress で Load Balancer を作成すると、同一 namespace 内の Service にしか振り分けられないとか、単一の Cluster でしか使えないとか不都合な場合があります。その場合 Load Balancer 関連のリソースは Terraform で作成したくなりますが、NEG まで作らなければ BackendService を作成できません。 しかし、NEG は GKE のコントローラが作成するため、鶏卵問題で悲しい思いをしたことはないでしょうか。 この NEG は GKE が作るのを待たずに Terraform で作成することも可能だったのでそのメモです。 答えを先に書いておくと、次のようになります。 data \"google_compute_zones\" \"available\" {} resource \"google_compute_network_endpoint_group\" \"igw\" { for_each = toset([for zone in data.google_compute_zones.available.names : zone if substr(zone, 0, length(var.region)) == var.region]) […]GKE Service の NEG を Terraform で作成する first appeared on 1Q77.","link":"https://blog.1q77.com/2022/08/create-gke-service-neg-using-terraform/","isoDate":"2022-08-09T11:13:48.000Z","dateMiliSeconds":1660043628000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"istio-proxy の log level を変更する","contentSnippet":"Istio でよくわからない通信の問題が発生した際、Envoy の access log だけでは何が起きているのかわからない場合があります。そんなとき、当該 Pod の LogLevel を debug に変更することで得られる情報が増えることがあります。問題が再現しないとダメですが。 LogLevel は Pod の sidecar.istio.io/logLevel という annotation で指定可能です。 metadata: annotations: \"sidecar.istio.io/logLevel\": debug 選択肢は次の通り trace, debug, info, warning, error, critical, off Probe のアクセスが多くてノイズになる場合は readiness.status.sidecar.istio.io/periodSeconds という annotation で感覚を伸ばすこともできます。 metadata: annotations: \"sidecar.istio.io/logLevel\": debug \"readiness.status.sidecar.istio.io/periodSeconds\": \"60\" 参考情報 https://access.redhat.com/solutions/6303361istio-proxy の log level を変更する first appeared on 1Q77.","link":"https://blog.1q77.com/2022/06/istio-proxy-log-level/","isoDate":"2022-06-07T07:34:29.000Z","dateMiliSeconds":1654587269000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Mizu で kubernetes 内の通信を覗く (part 1)","contentSnippet":"Mizu – API Traffic viewer for Kubernetes というものの存在を知ったので試してみます。 サイトには次のように書いてあります。気になります。 Mizu offers a real-time view of all HTTP requests, REST and gRPC API calls, as well as Kafka, AMQP (activeMQ / RabbitMQ), and Redis. HTTP も gRPC も Redis や Kafka とかも通信内容を parse して見やすく表示してくれるそうな。 使い方を見ても mizu tap と実行するだけになっていて、マジで？？ という感じなので実際にやってみます。 例えば、Intel Mac なら次のようにして mizu バイナリをダウンロードして実行するだけ。インストール対象の Kubernetes にアクセスできるように […]Mizu で kubernetes 内の通信を覗く (part 1) first appeared on 1Q77.","link":"https://blog.1q77.com/2022/06/using-mizu-part-1/","isoDate":"2022-06-04T16:04:52.000Z","dateMiliSeconds":1654358692000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"istio sidecar の停止を connection がなくなるまで遅らせる","contentSnippet":"新機能 EXIT_ON_ZERO_ACTIVE_CONNECTIONS 以前、「Istio 導入への道 – sidecar の調整編」という記事で、Istio の sidecar (istio-proxy) が、アプリの終了を待たずに停止してしまってアプリ側が通信できなくなるという問題に対して preStop hook に netstat などを使った wait 処理を入れるというのを紹介しましたが、あれは listen しているプロセスがいなくなるまで待つというもので、nginx などのように処理中のリクエストは完了を待つが、listen している socket は signal を受けるとすぐに close するというサーバーの場合には有効に働きませんでした。これに対して 2021年11月にリリースされた Istio 1.12 では drain モードに変更した後、アクティブなコネクションがなくなるまで待つという設定ができるようになっていました。(drain モードについては後述) Istio 1.12 Change Notes に次のように書かれています。 Added support for envoy to track active connections during drain and quit if active connections […]istio sidecar の停止を connection がなくなるまで遅らせる first appeared on 1Q77.","link":"https://blog.1q77.com/2022/02/istio-exit-on-zero-active-connections/","isoDate":"2022-02-26T15:52:27.000Z","dateMiliSeconds":1645890747000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"telepresence 入門 (2)","contentSnippet":"前回の telepresence 入門 (1) の続きです。今回は Kubernetes クラスタの Service へのアクセスをインターセプトして手元の環境に転送することを試します。Kubernetes 側の volume も手元で mount させるし、環境変数も引っ張ってきます。 バージョンなど環境については前回と同じ。 インターセプト設定 Kubernetes の Service 宛の通信を手元に転送することを　intercept と呼ぶようです。 インターセプト前の状態 前回使った hello という Service, Deployment を使います。 $ kubectl create deploy hello --image=k8s.gcr.io/echoserver:1.4 $ kubectl expose deploy hello --port 80 --target-port 8080 Service は port 80 をコンテナの port 8080 に転送するようになっています。 $ kubectl get svc […]telepresence 入門 (2) first appeared on 1Q77.","link":"https://blog.1q77.com/2022/01/telepresence-part-2/","isoDate":"2022-01-08T05:27:39.000Z","dateMiliSeconds":1641619659000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Docker on Lima","contentSnippet":"以前、「Lima で nerdctl」という記事を書きました。その後、lima の VM 上で docker daemon を実行し、ホスト側から docker コマンドでアクセスするという方法があることを知りました。たまたま、brew upgrade を実行していたところ lima が 0.8.0 に更新されたのを見て Github の releases ページを見、試してみようかなと思ったのでメモです。 ちなみに、前回試した時のバージョンは 0.6.4 でした。 Docker 入りの VM を起動させる 私は brew のインストール先を $HOME にしていますが、brew で lima をインストールすると ~/.homebrew/Cellar/lima/0.8.0/share/doc/lima/examples/docker.yaml に docker 入りの VM を作成するための設定ファイルも一緒にインストールされています。これを使うことで簡単に VM が作成できます。次のように limactl start に続けてファイルの path を指定するだけです。 $ limactl start ~/.homebrew/Cellar/lima/0.8.0/share/doc/lima/examples/docker.yaml ファイルは URL […]Docker on Lima first appeared on 1Q77.","link":"https://blog.1q77.com/2022/01/docker-on-lima/","isoDate":"2022-01-04T16:23:46.000Z","dateMiliSeconds":1641313426000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"telepresence 入門 (1)","contentSnippet":"telepresence というツールがあります。手元の端末が Kubernetes クラスタ内にいるかのような通信を可能にし、Kubernetes の Pod の Container への通信をインターセプトして手元の端末に流すことができます。これの仕組みを調べてみます。(以前は Python で書かれていたようですが、v2 は Go で書き直されたみたいです) 確認に使用した telepresence と mac の version $ telepresence version Client: v2.4.9 (api v3) $ sw_vers ProductName: macOS ProductVersion: 12.1 BuildVersion: 21C52 Kubernetes クラスタは GKE の v1.21.5-gke.1302 クラスタへの terffic-manager のデプロイ helm を使ってインストールすることができます。デフォルトではクラスタワイドな設定になりますが、特定の namespace にのみインストールしたり、namespace 毎に権限を分けてインストールすることも可能です。 $ helm repo add datawire https://app.getambassador.io $ […]telepresence 入門 (1) first appeared on 1Q77.","link":"https://blog.1q77.com/2021/12/telepresence-part-1/","isoDate":"2021-12-31T14:54:43.000Z","dateMiliSeconds":1640962483000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"CloudFront のレスポンスに Security Headers を追加する","contentSnippet":"「Amazon CloudFront が設定可能な CORS、セキュリティ、およびカスタム HTTP レスポンスヘッダーをサポート」で Lambda@Edge なしで Response にカスタムヘッダーを追加することが可能になりました。 これを使って、このサイトにも Security Headers を追加してみます。 CloudFront のコンソールで、Policies → Response headers にアクセスすると Managed policies があり、次のポリシーが存在します。 CORS-and-SecurityHeadersPolicy CORS-With-Preflight CORS-with-preflight-and-SecurityHeadersPolicy SecurityHeadersPolicy SimpleCORS SecurityHeaders と CORS の組み合わせパターンですね。 SecurityHeadersPolicy ではレスポンスに次の Header がセットされます。 Strict-Transport-Security: max-age=31536000 X-Content-Type-Options: nosniff X-Frame-Options: SAMEORIGIN X-XSS-Protection: 1; mode=block Referrer-Policy: strict-origin-when-cross-origin これを Distributions → Behaviors の Response headers policy […]CloudFront のレスポンスに Security Headers を追加する first appeared on 1Q77.","link":"https://blog.1q77.com/2021/12/cloudfront-security-headers/","isoDate":"2021-12-31T07:28:54.000Z","dateMiliSeconds":1640935734000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"glibc, musl libc, go の resolver の違い","contentSnippet":"先日、resolv.conf で timeout を調整したいなと思うことがありました、しかし、Docker だの Kubernetes だのといった時代です。Linux しか使っていなかったとして…","link":"https://qiita.com/yteraoka/items/e74e8bf24f72f7ed5f15","isoDate":"2021-01-13T14:04:22.000Z","dateMiliSeconds":1610546662000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Istio の timeout, retry, circuit breaking, etc","link":"https://medium.com/sreake-jp/istio-%E3%81%AE-timeout-retry-circuit-breaking-etc-c170285447e8?source=rss-8b55af126a13------2","isoDate":"2020-10-17T14:52:08.000Z","dateMiliSeconds":1602946328000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Chaos Mesh によるカオスエンジニアリング","link":"https://medium.com/sreake-jp/chaos-mesh-%E3%81%AB%E3%82%88%E3%82%8B%E3%82%AB%E3%82%AA%E3%82%B9%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%83%AA%E3%83%B3%E3%82%B0-46fa2897c742?source=rss-8b55af126a13------2","isoDate":"2020-06-02T03:16:16.000Z","dateMiliSeconds":1591067776000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"Bitwardenで自分専用パスワードマネージャーサーバー構築","contentSnippet":"Qiita では初の Bitwarden 記事っぽい パスワードマネージャーサービスは有償、無償でいくつかありますが 1password.com がメジャーどころでしょうか。家族プランがあって良さげ…","link":"https://qiita.com/yteraoka/items/41faf5d183b997b66625","isoDate":"2017-12-22T03:02:36.000Z","dateMiliSeconds":1513911756000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"STNSの独自サーバーを書いてみた","contentSnippet":"オンプレサーバーに加え、複数のクラウドサービスや VPS を使うようになってくると Linux サーバーのアカウント管理が非常に面倒になってきました。（全てがコンテナと SaaS になるのはまだ先）そこで以前から気になっていた…","link":"https://qiita.com/yteraoka/items/77b329606f44b4e19b92","isoDate":"2017-12-11T05:03:26.000Z","dateMiliSeconds":1512968606000,"authorName":"yteraoka","authorId":"yteraoka"},{"title":"CentOS7でPostgreSQL 10のPacemakerクラスタ作成","contentSnippet":"クラウドのマネージドサービスが楽でいいよなぁと思いながら CentOS 7 + PostgreSQL 10 のサーバー3台で pacemaker を使ったクラスタを作成してみますTL;DRVag…","link":"https://qiita.com/yteraoka/items/cfa185f8846850648ab4","isoDate":"2017-12-07T14:39:03.000Z","dateMiliSeconds":1512657543000,"authorName":"yteraoka","authorId":"yteraoka"}]},"__N_SSG":true}